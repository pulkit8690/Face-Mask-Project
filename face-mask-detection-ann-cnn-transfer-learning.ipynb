{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.kaggle.com/code/pulkittarora/face-mask-detection-ann-cnn-transfer-learning?scriptVersionId=213978716\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#ecf0f1; color:#2c3e50; padding:15px; border-radius:10px; text-align:center; font-size:24px;\">\n",
    "    üì¶ Import Libraries\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T10:57:01.53252Z",
     "iopub.status.busy": "2024-10-25T10:57:01.532037Z",
     "iopub.status.idle": "2024-10-25T10:57:01.541693Z",
     "shell.execute_reply": "2024-10-25T10:57:01.540521Z",
     "shell.execute_reply.started": "2024-10-25T10:57:01.532464Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import cv2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#ecf0f1; color:#16a085; padding:15px; border-radius:10px; text-align:center; font-size:24px;\">\n",
    "    üìä Import Data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T10:57:01.543581Z",
     "iopub.status.busy": "2024-10-25T10:57:01.543267Z",
     "iopub.status.idle": "2024-10-25T10:57:01.560532Z",
     "shell.execute_reply": "2024-10-25T10:57:01.55974Z",
     "shell.execute_reply.started": "2024-10-25T10:57:01.54355Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to parse XML files\n",
    "def parse_xml(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Initialize variables for the image details\n",
    "    label = None\n",
    "\n",
    "    # Parse XML to get the label\n",
    "    for member in root.findall('object'):\n",
    "        label = member.find('name').text\n",
    "        # Assuming we only need the label, not bounding box coordinates\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T10:57:01.562118Z",
     "iopub.status.busy": "2024-10-25T10:57:01.561812Z",
     "iopub.status.idle": "2024-10-25T10:57:13.313691Z",
     "shell.execute_reply": "2024-10-25T10:57:13.312898Z",
     "shell.execute_reply.started": "2024-10-25T10:57:01.562088Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "annotations_dir = '/kaggle/input/face-mask-detection/annotations/'\n",
    "images_dir = '/kaggle/input/face-mask-detection/images/'\n",
    "\n",
    "# Initialize lists to hold data\n",
    "image_data = []\n",
    "labels = []\n",
    "\n",
    "# Loop over each XML file in the annotations folder\n",
    "for xml_file in os.listdir(annotations_dir):\n",
    "    if xml_file.endswith('.xml'):\n",
    "        # Parse the XML to get the label\n",
    "        xml_path = os.path.join(annotations_dir, xml_file)\n",
    "        label = parse_xml(xml_path)\n",
    "\n",
    "        # Corresponding image file\n",
    "        image_file = xml_file.replace('.xml', '.png')\n",
    "        image_path = os.path.join(images_dir, image_file)\n",
    "        \n",
    "        # Check if the image file exists\n",
    "        if os.path.exists(image_path):\n",
    "            # Read and resize image\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.resize(image, (128, 128))  # Resize to 128x128\n",
    "\n",
    "            # Flatten the image for ANN\n",
    "            image_flat = image.flatten()\n",
    "\n",
    "            # Append data to lists\n",
    "            image_data.append(image_flat)\n",
    "            labels.append(label)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(image_data)\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T10:57:13.316744Z",
     "iopub.status.busy": "2024-10-25T10:57:13.316259Z",
     "iopub.status.idle": "2024-10-25T10:57:13.32368Z",
     "shell.execute_reply": "2024-10-25T10:57:13.322873Z",
     "shell.execute_reply.started": "2024-10-25T10:57:13.316699Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Encode labels (e.g., 'with_mask' -> 0, 'without_mask' -> 1)\n",
    "label_encoder = LabelBinarizer()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T10:57:13.325002Z",
     "iopub.status.busy": "2024-10-25T10:57:13.32469Z",
     "iopub.status.idle": "2024-10-25T10:57:13.332867Z",
     "shell.execute_reply": "2024-10-25T10:57:13.332085Z",
     "shell.execute_reply.started": "2024-10-25T10:57:13.32495Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert y_encoded to a Numpy array \n",
    "y_encoded = np.array(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T10:57:13.33431Z",
     "iopub.status.busy": "2024-10-25T10:57:13.334051Z",
     "iopub.status.idle": "2024-10-25T10:57:13.345689Z",
     "shell.execute_reply": "2024-10-25T10:57:13.344675Z",
     "shell.execute_reply.started": "2024-10-25T10:57:13.334281Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert y_encoded to categorical if it's binary and single-label\n",
    "if len(y_encoded.shape) == 1:\n",
    "    print(\"true\")\n",
    "    y_encoded = to_categorical(y_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#8e44ad; color:white; padding:15px; border-radius:10px; text-align:center; font-size:24px;\">\n",
    "    üñºÔ∏è Visualization\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T10:57:13.346995Z",
     "iopub.status.busy": "2024-10-25T10:57:13.346723Z",
     "iopub.status.idle": "2024-10-25T10:57:14.763698Z",
     "shell.execute_reply": "2024-10-25T10:57:14.762431Z",
     "shell.execute_reply.started": "2024-10-25T10:57:13.346964Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to visualize images with their labels\n",
    "def visualize_images(X, y_encoded, label_encoder, num_images=10):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    indices = random.sample(range(len(X)), num_images)\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        # Reshape the flattened image back to original dimensions\n",
    "        image = X[idx].reshape(128, 128, 3)\n",
    "        \n",
    "        # Get the label index\n",
    "        label_index = y_encoded[idx]\n",
    "        \n",
    "        # Decode the label\n",
    "        label = label_encoder.inverse_transform([label_index])[0]\n",
    "        \n",
    "        # Plot each image in a grid\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.imshow(image.astype('uint8'))\n",
    "        plt.title(f'Label: {label}')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Fit the label encoder and transform labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Call the visualization function\n",
    "visualize_images(X, y_encoded, label_encoder, num_images=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#2980b9; color:#ffffff; padding:15px; border-radius:10px; text-align:center; font-size:24px;\">\n",
    "    üèóÔ∏è Model Building\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T10:57:14.765698Z",
     "iopub.status.busy": "2024-10-25T10:57:14.76531Z",
     "iopub.status.idle": "2024-10-25T10:57:14.975327Z",
     "shell.execute_reply": "2024-10-25T10:57:14.974338Z",
     "shell.execute_reply.started": "2024-10-25T10:57:14.765656Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Normalize pixel values to the range [0, 1]\n",
    "X_normalized = X / 255.0\n",
    "\n",
    "# One-hot encode labels for ANN \n",
    "y_encoded_one_hot = to_categorical(y_encoded)\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y_encoded_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shape of the training and testing data\n",
    "print(f\"Training data shape: {X_train.shape}, Training labels shape: {y_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}, Testing labels shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the Artificial Neural Network (ANN)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T10:57:14.979661Z",
     "iopub.status.busy": "2024-10-25T10:57:14.979335Z",
     "iopub.status.idle": "2024-10-25T10:57:15.037929Z",
     "shell.execute_reply": "2024-10-25T10:57:15.03703Z",
     "shell.execute_reply.started": "2024-10-25T10:57:14.979629Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Build the ANN model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(49152,)),  # Flatten the 128x128x3 image to a 1D vector\n",
    "    Dense(256, activation='relu'),  # Hidden layer with 256 neurons\n",
    "    Dropout(0.5),                   # Dropout layer for regularization\n",
    "    Dense(128, activation='relu'),  # Hidden layer with 128 neurons\n",
    "    Dropout(0.5),                   # Dropout layer for regularization\n",
    "    Dense(3, activation='softmax')  # Output layer for 3 classes (if one-hot encoded)\n",
    "])\n",
    "\n",
    "# Compile the model with an optimizer, loss, and evaluation metric\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T10:57:15.039523Z",
     "iopub.status.busy": "2024-10-25T10:57:15.039123Z",
     "iopub.status.idle": "2024-10-25T10:57:25.883612Z",
     "shell.execute_reply": "2024-10-25T10:57:25.882639Z",
     "shell.execute_reply.started": "2024-10-25T10:57:15.039461Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train the ANN model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,                  # Number of epochs to train\n",
    "    batch_size=32,              # Size of each training batch\n",
    "    validation_data=(X_test, y_test),  # Use the test set for validation\n",
    "    verbose=2                   # Verbose output\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T10:57:25.885777Z",
     "iopub.status.busy": "2024-10-25T10:57:25.885357Z",
     "iopub.status.idle": "2024-10-25T10:57:26.750348Z",
     "shell.execute_reply": "2024-10-25T10:57:26.749401Z",
     "shell.execute_reply.started": "2024-10-25T10:57:25.885733Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot training & validation accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T10:57:26.752111Z",
     "iopub.status.busy": "2024-10-25T10:57:26.751711Z",
     "iopub.status.idle": "2024-10-25T10:57:26.83571Z",
     "shell.execute_reply": "2024-10-25T10:57:26.834986Z",
     "shell.execute_reply.started": "2024-10-25T10:57:26.752061Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Build an improved ANN model with reduced regularization\n",
    "improved_model = Sequential([\n",
    "    Flatten(input_shape=(49152,)),  # Flatten the 128x128x3 image to a 1D vector\n",
    "    \n",
    "    # First Dense Block\n",
    "    Dense(1024, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),  # Reduced dropout rate\n",
    "    \n",
    "    # Second Dense Block\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # Third Dense Block\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # Fourth Dense Block\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # Output Layer for 3 classes\n",
    "    Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T10:57:26.83733Z",
     "iopub.status.busy": "2024-10-25T10:57:26.836876Z",
     "iopub.status.idle": "2024-10-25T10:57:26.86896Z",
     "shell.execute_reply": "2024-10-25T10:57:26.86811Z",
     "shell.execute_reply.started": "2024-10-25T10:57:26.837278Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Adjusted learning rate\n",
    "improved_optimizer = Adam(learning_rate=0.0005)\n",
    "\n",
    "# Compile the improved model\n",
    "improved_model.compile(optimizer=improved_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the improved model summary\n",
    "improved_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T10:57:26.870612Z",
     "iopub.status.busy": "2024-10-25T10:57:26.870219Z",
     "iopub.status.idle": "2024-10-25T10:57:52.911468Z",
     "shell.execute_reply": "2024-10-25T10:57:52.910676Z",
     "shell.execute_reply.started": "2024-10-25T10:57:26.87057Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Define Early Stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',        # Monitor the validation loss\n",
    "    patience=10,               # Stop if no improvement after 10 epochs\n",
    "    restore_best_weights=True  # Restore the best weights after stopping\n",
    ")\n",
    "\n",
    "# Define Learning Rate Scheduler\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    factor=0.5,           # Reduce the learning rate by a factor of 0.5\n",
    "    patience=3,           # Wait for 3 epochs without improvement\n",
    "    verbose=1,            # Verbosity mode\n",
    "    min_lr=1e-6           # Minimum learning rate\n",
    ")\n",
    "\n",
    "# Train the improved model\n",
    "history_improved = improved_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,  # Increased epochs\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping, lr_scheduler],  # Include early stopping and learning rate scheduler\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T10:57:52.913176Z",
     "iopub.status.busy": "2024-10-25T10:57:52.912872Z",
     "iopub.status.idle": "2024-10-25T10:57:53.637254Z",
     "shell.execute_reply": "2024-10-25T10:57:53.636334Z",
     "shell.execute_reply.started": "2024-10-25T10:57:52.913145Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the improved model on the test set\n",
    "test_loss, test_accuracy = improved_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy for Improved Model: {test_accuracy:.2f}\")\n",
    "\n",
    "# Plot learning curves for the improved model\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot training & validation accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_improved.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_improved.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Improved Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_improved.history['loss'], label='Training Loss')\n",
    "plt.plot(history_improved.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Improved Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us also try a CNN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T10:57:53.641698Z",
     "iopub.status.busy": "2024-10-25T10:57:53.641148Z",
     "iopub.status.idle": "2024-10-25T10:57:53.735337Z",
     "shell.execute_reply": "2024-10-25T10:57:53.73451Z",
     "shell.execute_reply.started": "2024-10-25T10:57:53.641662Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Reshape the input data to the original image shape (128x128x3)\n",
    "X_train_reshaped = X_train.reshape(-1, 128, 128, 3)\n",
    "X_test_reshaped = X_test.reshape(-1, 128, 128, 3)\n",
    "\n",
    "# Build a simple CNN model\n",
    "cnn_model = Sequential([\n",
    "    # First Convolutional Block\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    # Second Convolutional Block\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    # Third Convolutional Block\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    # Flatten and Dense Layers\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')  # Output layer for 3 classes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T10:57:53.736568Z",
     "iopub.status.busy": "2024-10-25T10:57:53.736281Z",
     "iopub.status.idle": "2024-10-25T10:58:14.710346Z",
     "shell.execute_reply": "2024-10-25T10:58:14.709447Z",
     "shell.execute_reply.started": "2024-10-25T10:57:53.73653Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Compile the CNN model\n",
    "cnn_optimizer = Adam(learning_rate=0.0001)\n",
    "cnn_model.compile(optimizer=cnn_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the CNN model summary\n",
    "cnn_model.summary()\n",
    "\n",
    "# Train the CNN model with Early Stopping\n",
    "history_cnn = cnn_model.fit(\n",
    "    X_train_reshaped, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test_reshaped, y_test),\n",
    "    callbacks=[early_stopping, lr_scheduler],  # Include early stopping and learning rate scheduler\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T10:58:14.712156Z",
     "iopub.status.busy": "2024-10-25T10:58:14.711851Z",
     "iopub.status.idle": "2024-10-25T10:58:15.379783Z",
     "shell.execute_reply": "2024-10-25T10:58:15.378869Z",
     "shell.execute_reply.started": "2024-10-25T10:58:14.712124Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the CNN model on the test set\n",
    "test_loss, test_accuracy = cnn_model.evaluate(X_test_reshaped, y_test, verbose=0)\n",
    "print(f\"Test Accuracy for CNN Model: {test_accuracy:.2f}\")\n",
    "\n",
    "# Plot learning curves for the CNN model\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot training & validation accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_cnn.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_cnn.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('CNN Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_cnn.history['loss'], label='Training Loss')\n",
    "plt.plot(history_cnn.history['val_loss'], label='Validation Loss')\n",
    "plt.title('CNN Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#2c3e50; color:#ffffff; padding:15px; border-radius:10px; text-align:center; font-size:24px;\">\n",
    "    üß† Pre-trained Model with Transfer Learning\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T10:58:15.381753Z",
     "iopub.status.busy": "2024-10-25T10:58:15.381314Z",
     "iopub.status.idle": "2024-10-25T10:58:16.166239Z",
     "shell.execute_reply": "2024-10-25T10:58:16.165475Z",
     "shell.execute_reply.started": "2024-10-25T10:58:15.381704Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "\n",
    "# Load MobileNetV2 with pre-trained weights, excluding the top classification layer\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom top layers for your specific dataset\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# Combine the base model with custom layers\n",
    "transfer_model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T10:58:16.167646Z",
     "iopub.status.busy": "2024-10-25T10:58:16.167324Z",
     "iopub.status.idle": "2024-10-25T10:58:43.442367Z",
     "shell.execute_reply": "2024-10-25T10:58:43.441552Z",
     "shell.execute_reply.started": "2024-10-25T10:58:16.167613Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Compile the transfer learning model\n",
    "transfer_optimizer = Adam(learning_rate=0.0001)\n",
    "transfer_model.compile(optimizer=transfer_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the transfer learning model summary\n",
    "transfer_model.summary()\n",
    "\n",
    "# Train the transfer learning model\n",
    "history_transfer = transfer_model.fit(\n",
    "    X_train_reshaped, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test_reshaped, y_test),\n",
    "    callbacks=[early_stopping, lr_scheduler],  # Include early stopping and learning rate scheduler\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T10:58:43.444123Z",
     "iopub.status.busy": "2024-10-25T10:58:43.443813Z",
     "iopub.status.idle": "2024-10-25T10:58:44.268435Z",
     "shell.execute_reply": "2024-10-25T10:58:44.267557Z",
     "shell.execute_reply.started": "2024-10-25T10:58:43.44409Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the transfer learning model on the test set\n",
    "test_loss, test_accuracy = transfer_model.evaluate(X_test_reshaped, y_test, verbose=0)\n",
    "print(f\"Test Accuracy for Transfer Learning Model: {test_accuracy:.2f}\")\n",
    "\n",
    "# Plot learning curves for the transfer learning model\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot training & validation accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_transfer.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_transfer.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Transfer Learning Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_transfer.history['loss'], label='Training Loss')\n",
    "plt.plot(history_transfer.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Transfer Learning Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T10:58:44.27029Z",
     "iopub.status.busy": "2024-10-25T10:58:44.269838Z",
     "iopub.status.idle": "2024-10-25T10:58:48.430556Z",
     "shell.execute_reply": "2024-10-25T10:58:48.429653Z",
     "shell.execute_reply.started": "2024-10-25T10:58:44.270243Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to visualize predictions from the transfer learning model\n",
    "def visualize_predictions(model, X_data, y_true, label_encoder, num_images=10):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Choose random indices to display\n",
    "    indices = np.random.choice(range(len(X_data)), num_images, replace=False)\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        # Get the image and true label\n",
    "        image = X_data[idx]\n",
    "        \n",
    "        # If the image is normalized (0-1), rescale it back to 0-255\n",
    "        if image.max() <= 1.0:\n",
    "            image = (image * 255).astype('uint8')\n",
    "        \n",
    "        # If the image is flattened, reshape it back to (128, 128, 3)\n",
    "        if image.shape != (128, 128, 3):\n",
    "            image = image.reshape(128, 128, 3)\n",
    "        \n",
    "        # Ensure the image data type is uint8 for visualization\n",
    "        if image.dtype != 'uint8':\n",
    "            image = image.astype('uint8')\n",
    "        \n",
    "        # Get the true label\n",
    "        true_label = label_encoder.inverse_transform([y_true[idx].argmax()])[0]\n",
    "        \n",
    "        # Predict the label using the transfer learning model\n",
    "        prediction = model.predict(np.expand_dims(image / 255.0, axis=0))  # Normalize image for prediction\n",
    "        predicted_label = label_encoder.inverse_transform([prediction.argmax()])[0]\n",
    "        \n",
    "        # Plot each image in a grid\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(f'True: {true_label}\\nPred: {predicted_label}')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the visualization function using the correct model name 'transfer_model'\n",
    "visualize_predictions(transfer_model, X_test_reshaped, y_test, label_encoder, num_images=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook Summary**\n",
    "\n",
    "I used three different classification approaches in an image in a mask detection task; namely, classifiers for maximum accuracy in terms of distinguishing between categories.\n",
    "\n",
    "1. Artificial Neural Network (ANN)\n",
    "\n",
    "Achieved Test Accuracy 0.75 (75%)\n",
    "Architecture: A Deep ANN with many fully connected layers and regularization techniques like dropout and L2 regularization.\n",
    "Observations\n",
    "ANN was able to capture simple patterns but not the spatial features of the images.\n",
    "The flatting into a 1D vector of the image data, which is spatially 2D, might explain the limitations in accuracy.\n",
    "Despite achieving accuracy of 75%, the ANN failed to fully exploit inherent spatial information in image data.\n",
    "2. Convolutional Neural Network (CNN)\n",
    "\n",
    "Test Accuracy Reached: 0.75 (75%)\n",
    "Architecture: Single simple CNN architecture with multiple convolutional layers, pooling, batch normalization, and dropout.\n",
    "Observations:\n",
    "So, CNNs have been designed natively better with handling the image data, because convolutional layers keep spatial relationships intact.\n",
    "Although the model applied convolutional filters, accuracy still had a stalemate at 75%, suggesting that further tuning or capacity of the model might be needed.\n",
    "Though similar in performance to ANN, CNN was able to attain this by performing better at feature extraction and thus better at the choice of model for image data.\n",
    "\n",
    "3. Transfer Learning (Pre-trained Model)\n",
    "\n",
    "Test Accuracy Achieved 0.80 80%\n",
    "Architecture: Transfer Learning of a pre-trained model: in this case, MobileNetV2, and appending custom dense layers for classification.\n",
    "Observations:\n",
    "Transfer learning was the best accuracy at 80% and performed better than both ANN and CNN.\n",
    "The pre-trained model worked very effectively to leverage features learned from big datasets such as ImageNet, thereby giving a marked performance boost.\n",
    "This can be learned with considerably greater efficiency and much faster than fine-tuning a pre-trained network.\n",
    "Transfer learning emerged to be the best performer in terms of both accuracy and training efficiency, through robust feature extraction from a pre-trained model.\n",
    "Comparison Overall\n",
    "ModelitectureTest Accuracy\\tKey Strengths\\tKey Limitations\n",
    "ANN\tFully connected layers\t0.75\tSimple, straightforward to implement\tStruggles with spatial features\n",
    "CNNConvolutional + pooling layers0.75Capture spatial features; more suitable for imagesTuning is necessary to optimize performance\n",
    "Transfer Learning Pre-trained + custom layers 0.80 Leverage pre-trained features, faster training Dependent on quality of pre-trained weights\n",
    "\n",
    "Key Takeaways\n",
    "\n",
    "ANN:\n",
    "This would classify generally, but not for image-based content and its spatial relationship.\n",
    "Accuracy was limited despite increasing complexity, indicating that ANNs are not the best choice for image-based tasks.\n",
    "\n",
    "CNN:\n",
    "Specially designed for images and has achieved similar performance to ANN but in a much more robust way.\n",
    "Although the CNNs may produce a better discernment of subtlety in images, more fine-tuning and possibly complexity may be required to attain stronger accuracy.\n",
    "\n",
    "Transfer Learning:\n",
    "Provided the best results with minimal training time.\n",
    "\n",
    "Benefited from features learned on large-scale datasets, making it more effective at handling image complexities.\n",
    "\n",
    "It gave an outstanding accuracy of 5% over ANN and CNN; hence, it is the best approach used so far.\n",
    "\n",
    "Future Recommendations for Improvement\n",
    "\n",
    "More Fine-Tuning In transfer learning, fine-tune deeper layers of the pre-trained model with the data to really capture features specific to the dataset.\n",
    "\n",
    "Ensemble Methods: Combine the predictions from multiple models with ANN, CNN, and even transfer learning to perhaps fine-tune accuracy.\n",
    "\n",
    "Data Augmentation: If the data augmentation hasn't been applied, consider increasing it for a further generalization and increase diversity in the dataset.\n",
    "\n",
    "Tuning Hyperparameters: Hyperparameter search (GridSearchCV and RandomSearch) should be performed to find the optimal set of learning rates, dropout rates, and batch sizes.\n",
    "\n",
    "We can try other pre-trained models, like ResNet, InceptionV3, and EfficientNet, to check if any of them happen to be better.\n",
    "\n",
    "**Conclusion**:\n",
    "\n",
    "The best strategy through this project was Transfer Learning, as it showed the power and potency of pre-trained models in image classification. ANN provided a great starting point for image analysis but might need to use more advanced configurations and data post-adjustments. ANN, although easier to implement, turned out pretty weak with the image data, so indeed, specialized architectures (like CNN or Ttansfer learning) are more suited for such tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#3498db; color:#ffffff; padding:20px; border-radius:15px; text-align:center; font-size:28px;\">\n",
    "    üåü Thank You for Visiting My Notebook! üåü\n",
    "</div>\n",
    "<div style=\"background-color:#3498db; color:#ffffff; padding:10px; border-radius:15px; text-align:center; font-size:20px;\">\n",
    "    Please do share and Upvote. Happy Learning! üöÄüìö\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 667889,
     "sourceId": 1176415,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
