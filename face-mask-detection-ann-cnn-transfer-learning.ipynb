{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1176415,"sourceType":"datasetVersion","datasetId":667889}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/pulkittarora/face-mask-detection-ann-cnn-transfer-learning?scriptVersionId=213978716\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<div style=\"background-color:#ecf0f1; color:#2c3e50; padding:15px; border-radius:10px; text-align:center; font-size:24px;\">\n    üì¶ Import Libraries\n</div>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nimport cv2\nfrom tensorflow.keras.optimizers import Adam\nimport xml.etree.ElementTree as ET\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom sklearn.model_selection import train_test_split\nimport os\n","metadata":{"execution":{"iopub.status.busy":"2024-10-25T10:57:01.532037Z","iopub.execute_input":"2024-10-25T10:57:01.53252Z","iopub.status.idle":"2024-10-25T10:57:01.541693Z","shell.execute_reply.started":"2024-10-25T10:57:01.532464Z","shell.execute_reply":"2024-10-25T10:57:01.540521Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"background-color:#ecf0f1; color:#16a085; padding:15px; border-radius:10px; text-align:center; font-size:24px;\">\n    üìä Import Data\n</div>","metadata":{}},{"cell_type":"code","source":"# Function to parse XML files\ndef parse_xml(xml_file):\n    tree = ET.parse(xml_file)\n    root = tree.getroot()\n\n    # Initialize variables for the image details\n    label = None\n\n    # Parse XML to get the label\n    for member in root.findall('object'):\n        label = member.find('name').text\n        # Assuming we only need the label, not bounding box coordinates\n\n    return label","metadata":{"execution":{"iopub.status.busy":"2024-10-25T10:57:01.543267Z","iopub.execute_input":"2024-10-25T10:57:01.543581Z","iopub.status.idle":"2024-10-25T10:57:01.560532Z","shell.execute_reply.started":"2024-10-25T10:57:01.54355Z","shell.execute_reply":"2024-10-25T10:57:01.55974Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Paths\nannotations_dir = '/kaggle/input/face-mask-detection/annotations/'\nimages_dir = '/kaggle/input/face-mask-detection/images/'\n\n# Initialize lists to hold data\nimage_data = []\nlabels = []\n\n# Loop over each XML file in the annotations folder\nfor xml_file in os.listdir(annotations_dir):\n    if xml_file.endswith('.xml'):\n        # Parse the XML to get the label\n        xml_path = os.path.join(annotations_dir, xml_file)\n        label = parse_xml(xml_path)\n\n        # Corresponding image file\n        image_file = xml_file.replace('.xml', '.png')\n        image_path = os.path.join(images_dir, image_file)\n        \n        # Check if the image file exists\n        if os.path.exists(image_path):\n            # Read and resize image\n            image = cv2.imread(image_path)\n            image = cv2.resize(image, (128, 128))  # Resize to 128x128\n\n            # Flatten the image for ANN\n            image_flat = image.flatten()\n\n            # Append data to lists\n            image_data.append(image_flat)\n            labels.append(label)\n\n# Convert to numpy arrays\nX = np.array(image_data)\ny = np.array(labels)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T10:57:01.561812Z","iopub.execute_input":"2024-10-25T10:57:01.562118Z","iopub.status.idle":"2024-10-25T10:57:13.313691Z","shell.execute_reply.started":"2024-10-25T10:57:01.562088Z","shell.execute_reply":"2024-10-25T10:57:13.312898Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import LabelBinarizer\n\n# Encode labels (e.g., 'with_mask' -> 0, 'without_mask' -> 1)\nlabel_encoder = LabelBinarizer()\ny_encoded = label_encoder.fit_transform(y)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T10:57:13.316259Z","iopub.execute_input":"2024-10-25T10:57:13.316744Z","iopub.status.idle":"2024-10-25T10:57:13.32368Z","shell.execute_reply.started":"2024-10-25T10:57:13.316699Z","shell.execute_reply":"2024-10-25T10:57:13.322873Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert y_encoded to a Numpy array \ny_encoded = np.array(y_encoded)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T10:57:13.32469Z","iopub.execute_input":"2024-10-25T10:57:13.325002Z","iopub.status.idle":"2024-10-25T10:57:13.332867Z","shell.execute_reply.started":"2024-10-25T10:57:13.32495Z","shell.execute_reply":"2024-10-25T10:57:13.332085Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert y_encoded to categorical if it's binary and single-label\nif len(y_encoded.shape) == 1:\n    print(\"true\")\n    y_encoded = to_categorical(y_encoded)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T10:57:13.334051Z","iopub.execute_input":"2024-10-25T10:57:13.33431Z","iopub.status.idle":"2024-10-25T10:57:13.345689Z","shell.execute_reply.started":"2024-10-25T10:57:13.334281Z","shell.execute_reply":"2024-10-25T10:57:13.344675Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"background-color:#8e44ad; color:white; padding:15px; border-radius:10px; text-align:center; font-size:24px;\">\n    üñºÔ∏è Visualization\n</div>","metadata":{}},{"cell_type":"code","source":"# Function to visualize images with their labels\ndef visualize_images(X, y_encoded, label_encoder, num_images=10):\n    plt.figure(figsize=(15, 10))\n    indices = random.sample(range(len(X)), num_images)\n    \n    for i, idx in enumerate(indices):\n        # Reshape the flattened image back to original dimensions\n        image = X[idx].reshape(128, 128, 3)\n        \n        # Get the label index\n        label_index = y_encoded[idx]\n        \n        # Decode the label\n        label = label_encoder.inverse_transform([label_index])[0]\n        \n        # Plot each image in a grid\n        plt.subplot(2, 5, i + 1)\n        plt.imshow(image.astype('uint8'))\n        plt.title(f'Label: {label}')\n        plt.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Fit the label encoder and transform labels\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\n# Call the visualization function\nvisualize_images(X, y_encoded, label_encoder, num_images=10)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T10:57:13.346723Z","iopub.execute_input":"2024-10-25T10:57:13.346995Z","iopub.status.idle":"2024-10-25T10:57:14.763698Z","shell.execute_reply.started":"2024-10-25T10:57:13.346964Z","shell.execute_reply":"2024-10-25T10:57:14.762431Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"background-color:#2980b9; color:#ffffff; padding:15px; border-radius:10px; text-align:center; font-size:24px;\">\n    üèóÔ∏è Model Building\n</div>","metadata":{}},{"cell_type":"code","source":"# Normalize pixel values to the range [0, 1]\nX_normalized = X / 255.0\n\n# One-hot encode labels for ANN \ny_encoded_one_hot = to_categorical(y_encoded)\n\n# Split the data into training and testing sets (80% training, 20% testing)\nX_train, X_test, y_train, y_test = train_test_split(X_normalized, y_encoded_one_hot, test_size=0.2, random_state=42)\n\n# Check the shape of the training and testing data\nprint(f\"Training data shape: {X_train.shape}, Training labels shape: {y_train.shape}\")\nprint(f\"Testing data shape: {X_test.shape}, Testing labels shape: {y_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-25T10:57:14.76531Z","iopub.execute_input":"2024-10-25T10:57:14.765698Z","iopub.status.idle":"2024-10-25T10:57:14.975327Z","shell.execute_reply.started":"2024-10-25T10:57:14.765656Z","shell.execute_reply":"2024-10-25T10:57:14.974338Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Building the Artificial Neural Network (ANN)**","metadata":{}},{"cell_type":"code","source":"# Build the ANN model\nmodel = Sequential([\n    Flatten(input_shape=(49152,)),  # Flatten the 128x128x3 image to a 1D vector\n    Dense(256, activation='relu'),  # Hidden layer with 256 neurons\n    Dropout(0.5),                   # Dropout layer for regularization\n    Dense(128, activation='relu'),  # Hidden layer with 128 neurons\n    Dropout(0.5),                   # Dropout layer for regularization\n    Dense(3, activation='softmax')  # Output layer for 3 classes (if one-hot encoded)\n])\n\n# Compile the model with an optimizer, loss, and evaluation metric\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Display the model's architecture\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-10-25T10:57:14.979335Z","iopub.execute_input":"2024-10-25T10:57:14.979661Z","iopub.status.idle":"2024-10-25T10:57:15.037929Z","shell.execute_reply.started":"2024-10-25T10:57:14.979629Z","shell.execute_reply":"2024-10-25T10:57:15.03703Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train the ANN model\nhistory = model.fit(\n    X_train, y_train,\n    epochs=20,                  # Number of epochs to train\n    batch_size=32,              # Size of each training batch\n    validation_data=(X_test, y_test),  # Use the test set for validation\n    verbose=2                   # Verbose output\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-25T10:57:15.039123Z","iopub.execute_input":"2024-10-25T10:57:15.039523Z","iopub.status.idle":"2024-10-25T10:57:25.883612Z","shell.execute_reply.started":"2024-10-25T10:57:15.039461Z","shell.execute_reply":"2024-10-25T10:57:25.882639Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate the model on the test set\ntest_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\nprint(f\"Test Accuracy: {test_accuracy:.2f}\")\n\n# Plot learning curves\nplt.figure(figsize=(14, 6))\n\n# Plot training & validation accuracy\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\n\n# Plot training & validation loss\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(loc='upper right')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-25T10:57:25.885357Z","iopub.execute_input":"2024-10-25T10:57:25.885777Z","iopub.status.idle":"2024-10-25T10:57:26.750348Z","shell.execute_reply.started":"2024-10-25T10:57:25.885733Z","shell.execute_reply":"2024-10-25T10:57:26.749401Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Build an improved ANN model with reduced regularization\nimproved_model = Sequential([\n    Flatten(input_shape=(49152,)),  # Flatten the 128x128x3 image to a 1D vector\n    \n    # First Dense Block\n    Dense(1024, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.3),  # Reduced dropout rate\n    \n    # Second Dense Block\n    Dense(512, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.3),\n    \n    # Third Dense Block\n    Dense(256, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.3),\n    \n    # Fourth Dense Block\n    Dense(128, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.3),\n    \n    # Output Layer for 3 classes\n    Dense(3, activation='softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2024-10-25T10:57:26.751711Z","iopub.execute_input":"2024-10-25T10:57:26.752111Z","iopub.status.idle":"2024-10-25T10:57:26.83571Z","shell.execute_reply.started":"2024-10-25T10:57:26.752061Z","shell.execute_reply":"2024-10-25T10:57:26.834986Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\n# Adjusted learning rate\nimproved_optimizer = Adam(learning_rate=0.0005)\n\n# Compile the improved model\nimproved_model.compile(optimizer=improved_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Display the improved model summary\nimproved_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-10-25T10:57:26.836876Z","iopub.execute_input":"2024-10-25T10:57:26.83733Z","iopub.status.idle":"2024-10-25T10:57:26.86896Z","shell.execute_reply.started":"2024-10-25T10:57:26.837278Z","shell.execute_reply":"2024-10-25T10:57:26.86811Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n# Define Early Stopping callback\nearly_stopping = EarlyStopping(\n    monitor='val_loss',        # Monitor the validation loss\n    patience=10,               # Stop if no improvement after 10 epochs\n    restore_best_weights=True  # Restore the best weights after stopping\n)\n\n# Define Learning Rate Scheduler\nlr_scheduler = ReduceLROnPlateau(\n    monitor='val_loss',  # Monitor validation loss\n    factor=0.5,           # Reduce the learning rate by a factor of 0.5\n    patience=3,           # Wait for 3 epochs without improvement\n    verbose=1,            # Verbosity mode\n    min_lr=1e-6           # Minimum learning rate\n)\n\n# Train the improved model\nhistory_improved = improved_model.fit(\n    X_train, y_train,\n    epochs=100,  # Increased epochs\n    batch_size=32,\n    validation_data=(X_test, y_test),\n    callbacks=[early_stopping, lr_scheduler],  # Include early stopping and learning rate scheduler\n    verbose=2\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T10:57:26.870219Z","iopub.execute_input":"2024-10-25T10:57:26.870612Z","iopub.status.idle":"2024-10-25T10:57:52.911468Z","shell.execute_reply.started":"2024-10-25T10:57:26.87057Z","shell.execute_reply":"2024-10-25T10:57:52.910676Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate the improved model on the test set\ntest_loss, test_accuracy = improved_model.evaluate(X_test, y_test, verbose=0)\nprint(f\"Test Accuracy for Improved Model: {test_accuracy:.2f}\")\n\n# Plot learning curves for the improved model\nplt.figure(figsize=(14, 6))\n\n# Plot training & validation accuracy\nplt.subplot(1, 2, 1)\nplt.plot(history_improved.history['accuracy'], label='Training Accuracy')\nplt.plot(history_improved.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Improved Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\n\n# Plot training & validation loss\nplt.subplot(1, 2, 2)\nplt.plot(history_improved.history['loss'], label='Training Loss')\nplt.plot(history_improved.history['val_loss'], label='Validation Loss')\nplt.title('Improved Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(loc='upper right')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-25T10:57:52.912872Z","iopub.execute_input":"2024-10-25T10:57:52.913176Z","iopub.status.idle":"2024-10-25T10:57:53.637254Z","shell.execute_reply.started":"2024-10-25T10:57:52.913145Z","shell.execute_reply":"2024-10-25T10:57:53.636334Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Let us also try a CNN model**","metadata":{}},{"cell_type":"code","source":"# Reshape the input data to the original image shape (128x128x3)\nX_train_reshaped = X_train.reshape(-1, 128, 128, 3)\nX_test_reshaped = X_test.reshape(-1, 128, 128, 3)\n\n# Build a simple CNN model\ncnn_model = Sequential([\n    # First Convolutional Block\n    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n    BatchNormalization(),\n    MaxPooling2D(pool_size=(2, 2)),\n    Dropout(0.25),\n    \n    # Second Convolutional Block\n    Conv2D(64, (3, 3), activation='relu'),\n    BatchNormalization(),\n    MaxPooling2D(pool_size=(2, 2)),\n    Dropout(0.25),\n    \n    # Third Convolutional Block\n    Conv2D(128, (3, 3), activation='relu'),\n    BatchNormalization(),\n    MaxPooling2D(pool_size=(2, 2)),\n    Dropout(0.4),\n    \n    # Flatten and Dense Layers\n    Flatten(),\n    Dense(128, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.5),\n    Dense(3, activation='softmax')  # Output layer for 3 classes\n])","metadata":{"execution":{"iopub.status.busy":"2024-10-25T10:57:53.641148Z","iopub.execute_input":"2024-10-25T10:57:53.641698Z","iopub.status.idle":"2024-10-25T10:57:53.735337Z","shell.execute_reply.started":"2024-10-25T10:57:53.641662Z","shell.execute_reply":"2024-10-25T10:57:53.73451Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compile the CNN model\ncnn_optimizer = Adam(learning_rate=0.0001)\ncnn_model.compile(optimizer=cnn_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Display the CNN model summary\ncnn_model.summary()\n\n# Train the CNN model with Early Stopping\nhistory_cnn = cnn_model.fit(\n    X_train_reshaped, y_train,\n    epochs=50,\n    batch_size=32,\n    validation_data=(X_test_reshaped, y_test),\n    callbacks=[early_stopping, lr_scheduler],  # Include early stopping and learning rate scheduler\n    verbose=2\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T10:57:53.736281Z","iopub.execute_input":"2024-10-25T10:57:53.736568Z","iopub.status.idle":"2024-10-25T10:58:14.710346Z","shell.execute_reply.started":"2024-10-25T10:57:53.73653Z","shell.execute_reply":"2024-10-25T10:58:14.709447Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate the CNN model on the test set\ntest_loss, test_accuracy = cnn_model.evaluate(X_test_reshaped, y_test, verbose=0)\nprint(f\"Test Accuracy for CNN Model: {test_accuracy:.2f}\")\n\n# Plot learning curves for the CNN model\nplt.figure(figsize=(14, 6))\n\n# Plot training & validation accuracy\nplt.subplot(1, 2, 1)\nplt.plot(history_cnn.history['accuracy'], label='Training Accuracy')\nplt.plot(history_cnn.history['val_accuracy'], label='Validation Accuracy')\nplt.title('CNN Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\n\n# Plot training & validation loss\nplt.subplot(1, 2, 2)\nplt.plot(history_cnn.history['loss'], label='Training Loss')\nplt.plot(history_cnn.history['val_loss'], label='Validation Loss')\nplt.title('CNN Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(loc='upper right')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-25T10:58:14.711851Z","iopub.execute_input":"2024-10-25T10:58:14.712156Z","iopub.status.idle":"2024-10-25T10:58:15.379783Z","shell.execute_reply.started":"2024-10-25T10:58:14.712124Z","shell.execute_reply":"2024-10-25T10:58:15.378869Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"background-color:#2c3e50; color:#ffffff; padding:15px; border-radius:10px; text-align:center; font-size:24px;\">\n    üß† Pre-trained Model with Transfer Learning\n</div>","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n\n# Load MobileNetV2 with pre-trained weights, excluding the top classification layer\nbase_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n\n# Freeze the base model layers\nbase_model.trainable = False\n\n# Add custom top layers for your specific dataset\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(128, activation='relu')(x)\nx = Dropout(0.5)(x)\npredictions = Dense(3, activation='softmax')(x)\n\n# Combine the base model with custom layers\ntransfer_model = Model(inputs=base_model.input, outputs=predictions)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T10:58:15.381314Z","iopub.execute_input":"2024-10-25T10:58:15.381753Z","iopub.status.idle":"2024-10-25T10:58:16.166239Z","shell.execute_reply.started":"2024-10-25T10:58:15.381704Z","shell.execute_reply":"2024-10-25T10:58:16.165475Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compile the transfer learning model\ntransfer_optimizer = Adam(learning_rate=0.0001)\ntransfer_model.compile(optimizer=transfer_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Display the transfer learning model summary\ntransfer_model.summary()\n\n# Train the transfer learning model\nhistory_transfer = transfer_model.fit(\n    X_train_reshaped, y_train,\n    epochs=30,\n    batch_size=32,\n    validation_data=(X_test_reshaped, y_test),\n    callbacks=[early_stopping, lr_scheduler],  # Include early stopping and learning rate scheduler\n    verbose=2\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T10:58:16.167324Z","iopub.execute_input":"2024-10-25T10:58:16.167646Z","iopub.status.idle":"2024-10-25T10:58:43.442367Z","shell.execute_reply.started":"2024-10-25T10:58:16.167613Z","shell.execute_reply":"2024-10-25T10:58:43.441552Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate the transfer learning model on the test set\ntest_loss, test_accuracy = transfer_model.evaluate(X_test_reshaped, y_test, verbose=0)\nprint(f\"Test Accuracy for Transfer Learning Model: {test_accuracy:.2f}\")\n\n# Plot learning curves for the transfer learning model\nplt.figure(figsize=(14, 6))\n\n# Plot training & validation accuracy\nplt.subplot(1, 2, 1)\nplt.plot(history_transfer.history['accuracy'], label='Training Accuracy')\nplt.plot(history_transfer.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Transfer Learning Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\n\n# Plot training & validation loss\nplt.subplot(1, 2, 2)\nplt.plot(history_transfer.history['loss'], label='Training Loss')\nplt.plot(history_transfer.history['val_loss'], label='Validation Loss')\nplt.title('Transfer Learning Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(loc='upper right')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-25T10:58:43.443813Z","iopub.execute_input":"2024-10-25T10:58:43.444123Z","iopub.status.idle":"2024-10-25T10:58:44.268435Z","shell.execute_reply.started":"2024-10-25T10:58:43.44409Z","shell.execute_reply":"2024-10-25T10:58:44.267557Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to visualize predictions from the transfer learning model\ndef visualize_predictions(model, X_data, y_true, label_encoder, num_images=10):\n    plt.figure(figsize=(15, 10))\n    \n    # Choose random indices to display\n    indices = np.random.choice(range(len(X_data)), num_images, replace=False)\n    \n    for i, idx in enumerate(indices):\n        # Get the image and true label\n        image = X_data[idx]\n        \n        # If the image is normalized (0-1), rescale it back to 0-255\n        if image.max() <= 1.0:\n            image = (image * 255).astype('uint8')\n        \n        # If the image is flattened, reshape it back to (128, 128, 3)\n        if image.shape != (128, 128, 3):\n            image = image.reshape(128, 128, 3)\n        \n        # Ensure the image data type is uint8 for visualization\n        if image.dtype != 'uint8':\n            image = image.astype('uint8')\n        \n        # Get the true label\n        true_label = label_encoder.inverse_transform([y_true[idx].argmax()])[0]\n        \n        # Predict the label using the transfer learning model\n        prediction = model.predict(np.expand_dims(image / 255.0, axis=0))  # Normalize image for prediction\n        predicted_label = label_encoder.inverse_transform([prediction.argmax()])[0]\n        \n        # Plot each image in a grid\n        plt.subplot(2, 5, i + 1)\n        plt.imshow(image)\n        plt.title(f'True: {true_label}\\nPred: {predicted_label}')\n        plt.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Call the visualization function using the correct model name 'transfer_model'\nvisualize_predictions(transfer_model, X_test_reshaped, y_test, label_encoder, num_images=10)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T10:58:44.269838Z","iopub.execute_input":"2024-10-25T10:58:44.27029Z","iopub.status.idle":"2024-10-25T10:58:48.430556Z","shell.execute_reply.started":"2024-10-25T10:58:44.270243Z","shell.execute_reply":"2024-10-25T10:58:48.429653Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Notebook Summary**\n\nI used three different classification approaches in an image in a mask detection task; namely, classifiers for maximum accuracy in terms of distinguishing between categories.\n\n1. Artificial Neural Network (ANN)\n\nAchieved Test Accuracy 0.75 (75%)\nArchitecture: A Deep ANN with many fully connected layers and regularization techniques like dropout and L2 regularization.\nObservations\nANN was able to capture simple patterns but not the spatial features of the images.\nThe flatting into a 1D vector of the image data, which is spatially 2D, might explain the limitations in accuracy.\nDespite achieving accuracy of 75%, the ANN failed to fully exploit inherent spatial information in image data.\n2. Convolutional Neural Network (CNN)\n\nTest Accuracy Reached: 0.75 (75%)\nArchitecture: Single simple CNN architecture with multiple convolutional layers, pooling, batch normalization, and dropout.\nObservations:\nSo, CNNs have been designed natively better with handling the image data, because convolutional layers keep spatial relationships intact.\nAlthough the model applied convolutional filters, accuracy still had a stalemate at 75%, suggesting that further tuning or capacity of the model might be needed.\nThough similar in performance to ANN, CNN was able to attain this by performing better at feature extraction and thus better at the choice of model for image data.\n\n3. Transfer Learning (Pre-trained Model)\n\nTest Accuracy Achieved 0.80 80%\nArchitecture: Transfer Learning of a pre-trained model: in this case, MobileNetV2, and appending custom dense layers for classification.\nObservations:\nTransfer learning was the best accuracy at 80% and performed better than both ANN and CNN.\nThe pre-trained model worked very effectively to leverage features learned from big datasets such as ImageNet, thereby giving a marked performance boost.\nThis can be learned with considerably greater efficiency and much faster than fine-tuning a pre-trained network.\nTransfer learning emerged to be the best performer in terms of both accuracy and training efficiency, through robust feature extraction from a pre-trained model.\nComparison Overall\nModelitectureTest Accuracy\\tKey Strengths\\tKey Limitations\nANN\tFully connected layers\t0.75\tSimple, straightforward to implement\tStruggles with spatial features\nCNNConvolutional + pooling layers0.75Capture spatial features; more suitable for imagesTuning is necessary to optimize performance\nTransfer Learning Pre-trained + custom layers 0.80 Leverage pre-trained features, faster training Dependent on quality of pre-trained weights\n\nKey Takeaways\n\nANN:\nThis would classify generally, but not for image-based content and its spatial relationship.\nAccuracy was limited despite increasing complexity, indicating that ANNs are not the best choice for image-based tasks.\n\nCNN:\nSpecially designed for images and has achieved similar performance to ANN but in a much more robust way.\nAlthough the CNNs may produce a better discernment of subtlety in images, more fine-tuning and possibly complexity may be required to attain stronger accuracy.\n\nTransfer Learning:\nProvided the best results with minimal training time.\n\nBenefited from features learned on large-scale datasets, making it more effective at handling image complexities.\n\nIt gave an outstanding accuracy of 5% over ANN and CNN; hence, it is the best approach used so far.\n\nFuture Recommendations for Improvement\n\nMore Fine-Tuning In transfer learning, fine-tune deeper layers of the pre-trained model with the data to really capture features specific to the dataset.\n\nEnsemble Methods: Combine the predictions from multiple models with ANN, CNN, and even transfer learning to perhaps fine-tune accuracy.\n\nData Augmentation: If the data augmentation hasn't been applied, consider increasing it for a further generalization and increase diversity in the dataset.\n\nTuning Hyperparameters: Hyperparameter search (GridSearchCV and RandomSearch) should be performed to find the optimal set of learning rates, dropout rates, and batch sizes.\n\nWe can try other pre-trained models, like ResNet, InceptionV3, and EfficientNet, to check if any of them happen to be better.\n\n**Conclusion**:\n\nThe best strategy through this project was Transfer Learning, as it showed the power and potency of pre-trained models in image classification. ANN provided a great starting point for image analysis but might need to use more advanced configurations and data post-adjustments. ANN, although easier to implement, turned out pretty weak with the image data, so indeed, specialized architectures (like CNN or Ttansfer learning) are more suited for such tasks.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color:#3498db; color:#ffffff; padding:20px; border-radius:15px; text-align:center; font-size:28px;\">\n    üåü Thank You for Visiting My Notebook! üåü\n</div>\n<div style=\"background-color:#3498db; color:#ffffff; padding:10px; border-radius:15px; text-align:center; font-size:20px;\">\n    Please do share and Upvote. Happy Learning! üöÄüìö\n</div>\n\n\n\n\n\n","metadata":{}}]}